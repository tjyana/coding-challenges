{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fullcycle example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_dataset.csv\")\n",
    "df.head()\n",
    "\n",
    "# check distribution, EDA etc\n",
    "df['quality rating'].value_counts()\n",
    "\n",
    "# feature engineering according to EDA\n",
    "# bin continuous values into 2 bins for even distribution\n",
    "df['binary quality'] = pd.cut(x = df['quality rating'], bins=2, labels=[0, 1])\n",
    "df['binary quality'].value_counts()\n",
    "\n",
    "# set X and y\n",
    "y = df['binary quality']\n",
    "X = df.drop(columns=['quality rating', 'binary quality'])\n",
    "\n",
    "# data preprocessing\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_scaled = mm_scaler.fit_transform(X)\n",
    "X_scaled\n",
    "\n",
    "\n",
    "# load model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(max_iter = 1000, loss='log_loss')\n",
    "\n",
    "# fit model\n",
    "sgd_model.fit(X_scaled, y)\n",
    "\n",
    "# prep new X (preprocess same way as other X)\n",
    "# only TRANSFORM. do not fit\n",
    "X_new = mm_scaler.transform(new_wine)\n",
    "\n",
    "# new datapoint to predict\n",
    "new_wine = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_new_wine.csv')\n",
    "new_wine\n",
    "\n",
    "# predict class\n",
    "predicted_class = sgd_model.predict(X_new)\n",
    "\n",
    "# predict proba of classes\n",
    "predicted_proba_of_class = sgd_model.predict_proba(X_new)[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122870d3",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "\n",
    "# Introduction to Machine Learning\n",
    "## Definition and Overview\n",
    "### What is Machine Learning?\n",
    "### History and Evolution\n",
    "### Key Concepts and Terminology\n",
    "## Types of Machine Learning\n",
    "### Supervised Learning\n",
    "#### Definition and Examples\n",
    "#### Use Cases\n",
    "#### Algorithms (e.g., `LinearRegression` from `sklearn.linear_model`)\n",
    "### Unsupervised Learning\n",
    "#### Definition and Examples\n",
    "#### Use Cases\n",
    "#### Algorithms (e.g., `KMeans` from `sklearn.cluster`)\n",
    "### Semi-supervised Learning\n",
    "#### Definition and Examples\n",
    "#### Use Cases\n",
    "#### Algorithms (e.g., Self-Training from `sklearn.semi_supervised`)\n",
    "### Reinforcement Learning\n",
    "#### Definition and Examples\n",
    "#### Use Cases\n",
    "#### Algorithms (e.g., Q-Learning, Deep Q-Networks with `tensorflow` or `pytorch`)\n",
    "## Applications of Machine Learning\n",
    "### Healthcare\n",
    "### Finance\n",
    "### Retail\n",
    "### Autonomous Vehicles\n",
    "### Natural Language Processing\n",
    "\n",
    "# Data Preprocessing\n",
    "## Data Cleaning\n",
    "### Handling Missing Values\n",
    "#### Mean/Median Imputation (e.g., `SimpleImputer` from `sklearn.impute`)\n",
    "#### Dropping Missing Values (e.g., `dropna()` from `pandas`)\n",
    "#### Filling with Forward/Backward Fill (e.g., `fillna(method='ffill')` from `pandas`)\n",
    "### Handling Outliers\n",
    "#### Z-Score Method (e.g., `scipy.stats.zscore`)\n",
    "#### IQR Method (e.g., using `quantile` from `pandas`)\n",
    "#### Winsorization (e.g., `winsorize` from `scipy.stats.mstats`)\n",
    "## Data Transformation\n",
    "### Encoding Categorical Variables\n",
    "#### One-Hot Encoding (e.g., `OneHotEncoder` from `sklearn.preprocessing`)\n",
    "#### Label Encoding (e.g., `LabelEncoder` from `sklearn.preprocessing`)\n",
    "#### Binary Encoding (e.g., `binary` from `category_encoders`)\n",
    "### Feature Scaling\n",
    "#### Normalization (Min-Max Scaling) (e.g., `MinMaxScaler` from `sklearn.preprocessing`)\n",
    "#### Standardization (Z-Score Scaling) (e.g., `StandardScaler` from `sklearn.preprocessing`)\n",
    "### Feature Engineering\n",
    "#### Creating New Features (e.g., using `pandas`)\n",
    "#### Polynomial Features (e.g., `PolynomialFeatures` from `sklearn.preprocessing`)\n",
    "#### Interaction Features (e.g., using `pandas` and custom functions)\n",
    "#### Log Transformations (e.g., `numpy.log`)\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "## Descriptive Statistics\n",
    "### Measures of Central Tendency (Mean, Median, Mode) (e.g., `mean`, `median`, `mode` from `numpy` or `pandas`)\n",
    "### Measures of Dispersion (Variance, Standard Deviation, Range) (e.g., `var`, `std` from `numpy` or `pandas`)\n",
    "### Skewness and Kurtosis (e.g., `skew`, `kurtosis` from `scipy.stats`)\n",
    "## Data Visualization Techniques\n",
    "### Histograms (e.g., `hist` from `matplotlib.pyplot` or `seaborn`)\n",
    "### Box Plots (e.g., `boxplot` from `matplotlib.pyplot` or `seaborn`)\n",
    "### Scatter Plots (e.g., `scatter` from `matplotlib.pyplot` or `seaborn`)\n",
    "### Pair Plots (e.g., `pairplot` from `seaborn`)\n",
    "### Heatmaps (e.g., `heatmap` from `seaborn`)\n",
    "### Violin Plots (e.g., `violinplot` from `seaborn`)\n",
    "## Identifying Patterns and Relationships\n",
    "### Correlation Analysis\n",
    "#### Pearson Correlation (e.g., `corr` from `pandas`)\n",
    "#### Spearman Correlation (e.g., `spearmanr` from `scipy.stats`)\n",
    "### Trend Analysis (e.g., using `pandas` time series methods)\n",
    "### Detecting Seasonality (e.g., using `statsmodels.tsa`)\n",
    "\n",
    "# Supervised Learning\n",
    "## Regression Algorithms\n",
    "### Linear Regression\n",
    "#### Assumptions\n",
    "#### Model Building (e.g., `LinearRegression` from `sklearn.linear_model`)\n",
    "#### Evaluation Metrics (MSE, RMSE, R²) (e.g., `mean_squared_error`, `r2_score` from `sklearn.metrics`)\n",
    "### Polynomial Regression\n",
    "#### Polynomial Features (e.g., `PolynomialFeatures` from `sklearn.preprocessing`)\n",
    "#### Overfitting and Underfitting\n",
    "### Ridge and Lasso Regression\n",
    "#### Regularization Techniques (e.g., `Ridge`, `Lasso` from `sklearn.linear_model`)\n",
    "#### Hyperparameter Tuning (α) (e.g., `GridSearchCV` from `sklearn.model_selection`)\n",
    "### Support Vector Regression\n",
    "#### Kernel Trick (e.g., `SVR` from `sklearn.svm`)\n",
    "#### Epsilon-Insensitive Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046aa83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72f45e17",
   "metadata": {},
   "source": [
    "## Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd8534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad06a7a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fullcycle example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_dataset.csv\")\n",
    "df.head()\n",
    "\n",
    "# check distribution, EDA etc\n",
    "df['quality rating'].value_counts()\n",
    "\n",
    "# feature engineering according to EDA\n",
    "# bin continuous values into 2 bins for even distribution\n",
    "df['binary quality'] = pd.cut(x = df['quality rating'], bins=2, labels=[0, 1])\n",
    "df['binary quality'].value_counts()\n",
    "\n",
    "# set X and y\n",
    "y = df['binary quality']\n",
    "X = df.drop(columns=['quality rating', 'binary quality'])\n",
    "\n",
    "# data preprocessing\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_scaled = mm_scaler.fit_transform(X)\n",
    "X_scaled\n",
    "\n",
    "\n",
    "# load model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(max_iter = 1000, loss='log_loss')\n",
    "\n",
    "# fit model\n",
    "sgd_model.fit(X_scaled, y)\n",
    "\n",
    "# prep new X (preprocess same way as other X)\n",
    "# only TRANSFORM. do not fit\n",
    "X_new = mm_scaler.transform(new_wine)\n",
    "\n",
    "# new datapoint to predict\n",
    "new_wine = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_new_wine.csv')\n",
    "new_wine\n",
    "\n",
    "# predict class\n",
    "predicted_class = sgd_model.predict(X_new)\n",
    "\n",
    "# predict proba of classes\n",
    "predicted_proba_of_class = sgd_model.predict_proba(X_new)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d53d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6296654e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da96f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf470966",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "#### Thresholding\n",
    "#### ROC Curve and AUC (e.g., `roc_curve`, `auc` from `sklearn.metrics`)\n",
    "### k-Nearest Neighbors (k-NN)\n",
    "#### Distance Metrics (Euclidean, Manhattan) (e.g., `KNeighborsClassifier` from `sklearn.neighbors`)\n",
    "#### Choosing k\n",
    "### Support Vector Machines (SVM)\n",
    "#### Linear SVM\n",
    "#### Kernel SVM (RBF, Polynomial) (e.g., `SVC` from `sklearn.svm`)\n",
    "#### Hyperparameters (C, Gamma)\n",
    "### Decision Trees\n",
    "#### Splitting Criteria (Gini, Entropy) (e.g., `DecisionTreeClassifier` from `sklearn.tree`)\n",
    "#### Pruning Techniques\n",
    "### Random Forests\n",
    "#### Bagging (e.g., `RandomForestClassifier` from `sklearn.ensemble`)\n",
    "#### Feature Importance\n",
    "### Gradient Boosting\n",
    "#### Boosting Principle\n",
    "#### Variants (AdaBoost, Gradient Boosting, XGBoost, LightGBM) (e.g., `GradientBoostingClassifier`, `XGBClassifier`, `LGBMClassifier`)\n",
    "### Neural Networks\n",
    "#### Perceptrons\n",
    "#### Multilayer Perceptrons (MLP) (e.g., `MLPClassifier` from `sklearn.neural_network`)\n",
    "#### Activation Functions (ReLU, Sigmoid, Tanh)\n",
    "\n",
    "# Unsupervised Learning\n",
    "## Clustering Algorithms\n",
    "### k-Means Clustering\n",
    "#### Choosing k (Elbow Method, Silhouette Score)\n",
    "#### Initial Centroid Selection (e.g., `KMeans` from `sklearn.cluster`)\n",
    "### Hierarchical Clustering\n",
    "#### Agglomerative vs. Divisive\n",
    "#### Dendrograms (e.g., `AgglomerativeClustering` from `sklearn.cluster`, `dendrogram` from `scipy.cluster.hierarchy`)\n",
    "### DBSCAN\n",
    "#### Density-Based Clustering\n",
    "#### Parameters (Epsilon, MinPts) (e.g., `DBSCAN` from `sklearn.cluster`)\n",
    "## Dimensionality Reduction\n",
    "### Principal Component Analysis (PCA)\n",
    "#### Eigenvalues and Eigenvectors\n",
    "#### Explained Variance Ratio (e.g., `PCA` from `sklearn.decomposition`)\n",
    "### t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "#### Perplexity\n",
    "#### Use Cases (e.g., `TSNE` from `sklearn.manifold`)\n",
    "### Linear Discriminant Analysis (LDA)\n",
    "#### Maximizing Class Separability\n",
    "#### Comparison with PCA (e.g., `LinearDiscriminantAnalysis` from `sklearn.discriminant_analysis`)\n",
    "\n",
    "# Semi-Supervised Learning\n",
    "## Self-Training\n",
    "### Pseudo-Labeling\n",
    "#### Confidence Thresholds\n",
    "#### Iterative Refinement\n",
    "## Co-Training\n",
    "### View Selection\n",
    "#### Independent Feature Sets\n",
    "## Graph-Based Semi-Supervised Learning\n",
    "### Label Propagation (e.g., `LabelPropagation` from `sklearn.semi_supervised`)\n",
    "### Graph Convolutional Networks\n",
    "\n",
    "# Reinforcement Learning\n",
    "## Introduction to Reinforcement Learning\n",
    "### Basics of RL\n",
    "### Key Concepts: Agent, Environment, State, Action, Reward\n",
    "## Markov Decision Processes (MDP)\n",
    "### States and Actions\n",
    "### Transition Probabilities\n",
    "### Rewards\n",
    "## Q-Learning\n",
    "### Q-Table\n",
    "### Bellman Equation\n",
    "### Exploration vs. Exploitation\n",
    "## Deep Q-Networks (DQN)\n",
    "### Neural Network Architecture (e.g., using `tensorflow` or `pytorch`)\n",
    "### Experience Replay\n",
    "### Target Networks\n",
    "## Policy Gradient Methods\n",
    "### REINFORCE Algorithm\n",
    "### Actor-Critic Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21fa69",
   "metadata": {},
   "source": [
    "# Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2780d2e",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5acfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe49f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b407649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228f88f9",
   "metadata": {},
   "source": [
    "### Holdout Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5714af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c720458",
   "metadata": {},
   "source": [
    "### Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf200e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "234954fa",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f8f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6428cff2",
   "metadata": {},
   "source": [
    "### k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ac1e7",
   "metadata": {},
   "source": [
    "#### using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380af839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/movie_reviews.csv')\n",
    "\n",
    "# import model to evaluate\n",
    "model = LinearRegression()\n",
    "\n",
    "# define X and y from dataset\n",
    "y = df['target']\n",
    "X = df.drop(columns='target')\n",
    "\n",
    "# use cross_val_score to get scores\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# average out to get final answer\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57207d1",
   "metadata": {},
   "source": [
    "#### using cross_validate\n",
    "- It allows specifying multiple metrics for evaluation.\n",
    "- It returns a dict containing fit-times, score-times (and optionally training scores, fitted estimators, train-test split indices) in addition to the test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cross_validate\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/movie_reviews.csv')\n",
    "\n",
    "# import model to evaluate\n",
    "model = LinearRegression()\n",
    "\n",
    "# define X and y from dataset\n",
    "y = df['target']\n",
    "X = df.drop(columns='target')\n",
    "\n",
    "# set scoring metrics you want to look at. can be tuple as well\n",
    "# can also shove in a dict where the keys are the metric names and the values are the scores \n",
    "scoring = ['r2', 'neg_mean_squared_error']\n",
    "\n",
    "# use cross_val_score to get scores\n",
    "scores = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# average out to get final answer\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd0e3b",
   "metadata": {},
   "source": [
    "#### Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38bc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc33513",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ab2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48703bd3",
   "metadata": {},
   "source": [
    "#### Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba76932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05169e7e",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97892525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "982f75b4",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed149c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2a98cd",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2f496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f10eb55",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9295d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a9ade2",
   "metadata": {},
   "source": [
    "### R² Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e995e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "099889d7",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ce077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4de032f6",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- Sum of the correct predictions divided by the sum of the overall number of predictions\n",
    "- Ratio of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051debc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9da03449",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- Measures the ability of a model to avoid false alarms for a class, or the confidence of a model when predicting a specific class.\n",
    "- Ability to flag correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70cc9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0019b433",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- Measures the ability of the model to detect occurrences of a class.\n",
    "- Ability to flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843983d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120ea550",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "- A combination of precision and recall into a single metric.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20e876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa13ac94",
   "metadata": {},
   "source": [
    "### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeab29f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# define X and y\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mClass\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# scale X\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# load model\n",
    "model = LogisticRegression(max_iter=2000, class_weight = 'balanced')\n",
    "\n",
    "# define X and y\n",
    "X = data.drop(columns='Class')\n",
    "y = data.Class\n",
    "\n",
    "# scale X\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Get baseline score for whatever metric. Recall in this case\n",
    "scoring = 'recall'\n",
    "scores = cross_val_score(model, X_scaled, y, cv=5, scoring=scoring)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db348e",
   "metadata": {},
   "source": [
    "##### get the threshold for 90% recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# get preds\n",
    "# preds returns: probs for class 0 and class 1\n",
    "# remember to do method = 'predict_proba' for probabilities. otherwise predicts straight up class\n",
    "preds = cross_val_predict(model, X_scaled, y, cv=5, method = \"predict_proba\")\n",
    "# get pred for class 1\n",
    "y_pred_1 = preds[:, 1]\n",
    "\n",
    "# use precision_recall_curve to get precision, recall, threshold\n",
    "precision, recall, threshold = precision_recall_curve(y, y_pred_1)\n",
    "\n",
    "# get all the indexes where recall is 90%+ \n",
    "above90 = np.where(recall >= 0.90)\n",
    "\n",
    "# Recall = ability to find all true positives\n",
    "# Recall DECREASES as threshold increases -> find max() threshold \n",
    "# Precision = ability to avoid false alarms\n",
    "# Precision INCREASES as threshold increases -> find min()\n",
    "threshold_index = above90[0].max()\n",
    "threshold[threshold_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f123e1",
   "metadata": {},
   "source": [
    "### ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e90156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "257db818",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82fdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "688b83c7",
   "metadata": {},
   "source": [
    "## Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387bebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4efc655",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7ebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b22bc659",
   "metadata": {},
   "source": [
    "### Techniques to Mitigate Overfitting (Regularization, Pruning, Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5c453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2871b74b",
   "metadata": {},
   "source": [
    "## Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5452ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e2cb16",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc92cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couple go to a church party drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>the happy bastard quick movie review damn that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>it is movie like these that make a jaded movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest for camelot is warner bros first feature...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>pos</td>\n",
       "      <td>wow ! what a movie . \\nit's everything a movie...</td>\n",
       "      <td>wow what a movie it everything a movie can be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>pos</td>\n",
       "      <td>richard gere can be a commanding actor , but h...</td>\n",
       "      <td>richard gere can be a commanding actor but he ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>pos</td>\n",
       "      <td>glory--starring matthew broderick , denzel was...</td>\n",
       "      <td>glorystarring matthew broderick denzel washing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>pos</td>\n",
       "      <td>steven spielberg's second epic film on world w...</td>\n",
       "      <td>steven spielberg second epic film on world war...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>pos</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "      <td>truman trueman burbank is the perfect name for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 target                                            reviews  \\\n",
       "0              0    neg  plot : two teen couples go to a church party ,...   \n",
       "1              1    neg  the happy bastard's quick movie review \\ndamn ...   \n",
       "2              2    neg  it is movies like these that make a jaded movi...   \n",
       "3              3    neg   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4              4    neg  synopsis : a mentally unstable man undergoing ...   \n",
       "...          ...    ...                                                ...   \n",
       "1995        1995    pos  wow ! what a movie . \\nit's everything a movie...   \n",
       "1996        1996    pos  richard gere can be a commanding actor , but h...   \n",
       "1997        1997    pos  glory--starring matthew broderick , denzel was...   \n",
       "1998        1998    pos  steven spielberg's second epic film on world w...   \n",
       "1999        1999    pos  truman ( \" true-man \" ) burbank is the perfect...   \n",
       "\n",
       "                                          clean_reviews  target_encoded  \n",
       "0     plot two teen couple go to a church party drin...               0  \n",
       "1     the happy bastard quick movie review damn that...               0  \n",
       "2     it is movie like these that make a jaded movie...               0  \n",
       "3     quest for camelot is warner bros first feature...               0  \n",
       "4     synopsis a mentally unstable man undergoing ps...               0  \n",
       "...                                                 ...             ...  \n",
       "1995  wow what a movie it everything a movie can be ...               1  \n",
       "1996  richard gere can be a commanding actor but he ...               1  \n",
       "1997  glorystarring matthew broderick denzel washing...               1  \n",
       "1998  steven spielberg second epic film on world war...               1  \n",
       "1999  truman trueman burbank is the perfect name for...               1  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/movie_reviews.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61aa7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;nb__alpha&#x27;: (0.01, 0.1, 1, 10),\n",
       "                         &#x27;tfidf__max_df&#x27;: (0.8, 0.9),\n",
       "                         &#x27;tfidf__min_df&#x27;: (0.01, 0.05),\n",
       "                         &#x27;tfidf__ngram_range&#x27;: ((1, 1), (2, 2), (3, 3))},\n",
       "             scoring=&#x27;recall&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;nb__alpha&#x27;: (0.01, 0.1, 1, 10),\n",
       "                         &#x27;tfidf__max_df&#x27;: (0.8, 0.9),\n",
       "                         &#x27;tfidf__min_df&#x27;: (0.01, 0.05),\n",
       "                         &#x27;tfidf__ngram_range&#x27;: ((1, 1), (2, 2), (3, 3))},\n",
       "             scoring=&#x27;recall&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'nb__alpha': (0.01, 0.1, 1, 10),\n",
       "                         'tfidf__max_df': (0.8, 0.9),\n",
       "                         'tfidf__min_df': (0.01, 0.05),\n",
       "                         'tfidf__ngram_range': ((1, 1), (2, 2), (3, 3))},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import set_config; set_config(\"diagram\")\n",
    "\n",
    "# import data\n",
    "data = pd.read_csv('data/movie_reviews.csv')\n",
    "\n",
    "# Create Pipeline\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = MultinomialNB()\n",
    "\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('tfidf', vectorizer), \n",
    "    ('nb', model)\n",
    "])\n",
    "\n",
    "# Set parameters you want to search through\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2), (3,3)),\n",
    "    'tfidf__min_df': (0.01,0.05),\n",
    "    'tfidf__max_df': (0.8,0.9),\n",
    "    'nb__alpha': (0.01,0.1,1,10)\n",
    "}\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_tfidf,\n",
    "    parameters,\n",
    "    scoring = \"recall\",\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit it on the data\n",
    "grid_search.fit(data.clean_reviews, data.target_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9b296c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb298777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 10,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__min_df': 0.01,\n",
       " 'tfidf__ngram_range': (2, 2)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best params\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1cac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=0.01, ngram_range=(2, 2))),\n",
       "                (&#x27;nb&#x27;, MultinomialNB(alpha=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=0.01, ngram_range=(2, 2))),\n",
       "                (&#x27;nb&#x27;, MultinomialNB(alpha=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.9, min_df=0.01, ngram_range=(2, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=0.01, ngram_range=(2, 2))),\n",
       "                ('nb', MultinomialNB(alpha=10))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best estimator\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1649d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd7b451",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab141b",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "## Bagging\n",
    "### Bootstrap Aggregating\n",
    "### Random Forests\n",
    "#### Out-of-Bag Error\n",
    "## Boosting\n",
    "### AdaBoost\n",
    "#### Weight Updates\n",
    "### Gradient Boosting\n",
    "#### Gradient Descent\n",
    "#### Learning Rate\n",
    "### XGBoost\n",
    "#### Regularization Parameters\n",
    "### LightGBM\n",
    "#### Leaf-wise Growth\n",
    "## Stacking\n",
    "### Base Models\n",
    "### Meta-Model\n",
    "## Voting Classifiers\n",
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7fd82f",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a28ebd",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "  ### Tokenization (e.g., `word_tokenize` from `nltk`, `Tokenizer` from `keras.preprocessing.text`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca094c",
   "metadata": {},
   "source": [
    "- Word Tokenization\n",
    "- Sentence Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b70e4e",
   "metadata": {},
   "source": [
    "  ### Stop Words Removal (e.g., `stopwords` from `nltk.corpus`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3795ef",
   "metadata": {},
   "source": [
    "  ### Stemming (e.g., `PorterStemmer` from `nltk.stem`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b5fe7",
   "metadata": {},
   "source": [
    "  ### Lemmatization (e.g., `WordNetLemmatizer` from `nltk.stem`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13745cad",
   "metadata": {},
   "source": [
    "  ### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06608ea3",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f1575",
   "metadata": {},
   "source": [
    "  ### Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ada635",
   "metadata": {},
   "source": [
    "#### Count Vectorization (e.g., `CountVectorizer` from `sklearn.feature_extraction.text`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a72682",
   "metadata": {},
   "source": [
    "##### Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55972283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'the young dog is running with the cat',\n",
    "    'running is good for your health',\n",
    "    'your cat is young',\n",
    "    'young young young young young cat cat cat'\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2139d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af366570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog', 'for', 'good', 'health', 'is', 'running', 'the',\n",
       "       'with', 'young', 'your'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9502ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert this to that grid thing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "vectorized_texts = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b867f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe360f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c03ae25e",
   "metadata": {},
   "source": [
    "##### Sparsity Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef864b",
   "metadata": {},
   "source": [
    "  ### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d0798",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization (e.g., `TfidfVectorizer` from `sklearn.feature_extraction.text`)\n",
    "      - Calculation\n",
    "      - Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ec077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couple go to a church party drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>the happy bastard quick movie review damn that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>it is movie like these that make a jaded movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest for camelot is warner bros first feature...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 target                                            reviews  \\\n",
       "0           0    neg  plot : two teen couples go to a church party ,...   \n",
       "1           1    neg  the happy bastard's quick movie review \\ndamn ...   \n",
       "2           2    neg  it is movies like these that make a jaded movi...   \n",
       "3           3    neg   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4           4    neg  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                       clean_reviews  target_encoded  \n",
       "0  plot two teen couple go to a church party drin...               0  \n",
       "1  the happy bastard quick movie review damn that...               0  \n",
       "2  it is movie like these that make a jaded movie...               0  \n",
       "3  quest for camelot is warner bros first feature...               0  \n",
       "4  synopsis a mentally unstable man undergoing ps...               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/movie_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b768783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x41596 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 643210 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying to column\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(data.clean_reviews)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbdfa9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# using pipeline\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Pipeline is probably simply better\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pipeline_tfidf_nb \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m([\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer()),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, MultinomialNB())\n\u001b[1;32m      7\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# using pipeline\n",
    "\n",
    "# Pipeline is probably simply better\n",
    "pipeline_tfidf_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# # make_pipeline is quicker but less customizable. can't give it the shortcuts for params:\n",
    "# pipeline_tfidf_nb = Pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     MultinomialNB())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29faba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validate\n",
    "\n",
    "cv_results = cross_validate(pipeline_tfidf_nb, X, y, cv=5, scoring='accuracy')\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8d989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f67e7b7",
   "metadata": {},
   "source": [
    "  ### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa4970",
   "metadata": {},
   "source": [
    "   #### Word2Vec (e.g., `Word2Vec` from `gensim.models`)\n",
    "        - CBOW and Skip-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133092d7",
   "metadata": {},
   "source": [
    "   #### GloVe (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01e2cc",
   "metadata": {},
   "source": [
    "   #### FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737ee88",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "  ### Naive Bayes Classifier\n",
    "    - Multinomial Naive Bayes (e.g., `MultinomialNB` from `sklearn.naive_bayes`)\n",
    "  ### Support Vector Machines (SVM)\n",
    "    - Linear SVM for Text Classification (e.g., `LinearSVC` from `sklearn.svm`)\n",
    "  ### Recurrent Neural Networks (RNN)\n",
    "    - Long Short-Term Memory Networks (LSTM) (e.g., `LSTM` from `keras.layers`)\n",
    "    - Gated Recurrent Units (GRU)\n",
    "  ### Transformer Models\n",
    "    - Encoder-Decoder Architecture\n",
    "    - BERT (e.g., `transformers.BertModel` from `transformers` library)\n",
    "    - GPT (e.g., `transformers.GPT2Model` from `transformers` library)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd0fc3",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "  ### Recurrent Neural Networks (RNN)\n",
    "    - Character-Level RNNs\n",
    "  ### Transformer Models\n",
    "    - GPT-3, GPT-4 (e.g., `OpenAI API`)\n",
    "  ### Retrieval-Augmented Generation (RAG)\n",
    "    - Combining Retrieval and Generation (e.g., `transformers.RagTokenizer`, `transformers.RagModel` from `transformers` library)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b16bd",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "- Time Series Decomposition\n",
    "  - Additive and Multiplicative Models\n",
    "  - Trend, Seasonality, and Residuals\n",
    "- ARIMA Models\n",
    "  - Autoregressive (AR)\n",
    "  - Integrated (I)\n",
    "  - Moving Average (MA)\n",
    "  - ARIMA Model Building\n",
    "- Exponential Smoothing\n",
    "  - Simple Exponential Smoothing\n",
    "  - Holt’s Linear Trend Model\n",
    "  - Holt-Winters Seasonal Model\n",
    "- Long Short-Term Memory (LSTM) for Time Series\n",
    "  - Sequence Prediction\n",
    "  - Handling Long Sequences\n",
    "\n",
    "# Anomaly Detection\n",
    "- Techniques and Algorithms\n",
    "  - Statistical Methods\n",
    "    - Z-Score (e.g., `scipy.stats.zscore`)\n",
    "    - Grubbs' Test\n",
    "  - Proximity-Based Methods\n",
    "    - k-Nearest Neighbors (k-NN) (e.g., `LocalOutlierFactor` from `sklearn.neighbors`)\n",
    "    - DBSCAN (e.g., `DBSCAN` from `sklearn.cluster`)\n",
    "  - Clustering-Based Methods\n",
    "    - k-Means Clustering (e.g., `KMeans` from `sklearn.cluster`)\n",
    "    - Isolation Forest (e.g., `IsolationForest` from `sklearn.ensemble`)\n",
    "  - Machine Learning-Based Methods\n",
    "    - One-Class SVM (e.g., `OneClassSVM` from `sklearn.svm`)\n",
    "    - Autoencoders (e.g., using `tensorflow.keras` or `pytorch`)\n",
    "\n",
    "# Model Deployment\n",
    "- Saving and Loading Models\n",
    "  - Using Pickle (e.g., `pickle.dump`, `pickle.load`)\n",
    "  - Using Joblib (e.g., `joblib.dump`, `joblib.load`)\n",
    "- Model Serving\n",
    "  - REST APIs (Flask, FastAPI)\n",
    "    - Building API Endpoints (e.g., `flask.Flask`, `fastapi.FastAPI`)\n",
    "    - Handling Requests and Responses\n",
    "  - Web Services (Django, Flask)\n",
    "    - Integrating Machine Learning Models\n",
    "    - Handling User Inputs (e.g., `django.http`, `django.views`)\n",
    "  - Cloud Services (AWS SageMaker, Google AI Platform)\n",
    "    - Deploying Models\n",
    "    - Monitoring and Scaling\n",
    "- Monitoring and Maintenance\n",
    "  - Model Performance Monitoring\n",
    "    - Tracking Metrics Over Time\n",
    "    - Setting Alerts for Degradation\n",
    "  - A/B Testing\n",
    "    - Designing Experiments\n",
    "    - Analyzing Results\n",
    "  - Model Retraining\n",
    "    - Triggering Retraining\n",
    "    - Automating Pipelines\n",
    "\n",
    "# Tools and Libraries\n",
    "- Python Libraries\n",
    "  - NumPy (e.g., `numpy.array`, `numpy.linalg`)\n",
    "  - pandas (e.g., `pandas.DataFrame`, `pandas.Series`)\n",
    "  - scikit-learn (e.g., `sklearn.preprocessing`, `sklearn.model_selection`)\n",
    "  - TensorFlow (e.g., `tensorflow.keras`, `tensorflow.data`)\n",
    "  - Keras (e.g., `keras.models`, `keras.layers`)\n",
    "  - PyTorch (e.g., `torch.Tensor`, `torch.nn`)\n",
    "  - SciPy (e.g., `scipy.stats`, `scipy.optimize`)\n",
    "- Data Visualization Libraries\n",
    "  - Matplotlib (e.g., `matplotlib.pyplot.plot`, `matplotlib.pyplot.show`)\n",
    "  - Seaborn (e.g., `seaborn.scatterplot`, `seaborn.heatmap`)\n",
    "  - Plotly (e.g., `plotly.graph_objs`, `plotly.express`)\n",
    "  - Bokeh (e.g., `bokeh.plotting.figure`, `bokeh.io.show`)\n",
    "  - Altair (e.g., `alt.Chart`, `alt.data_transformers`)\n",
    "- Tools for Model Deployment\n",
    "  - Flask (e.g., `flask.Flask`, `flask.request`)\n",
    "  - Django (e.g., `django.http`, `django.views`)\n",
    "  - FastAPI (e.g., `fastapi.FastAPI`, `fastapi.Request`)\n",
    "  - Docker (e.g., Dockerfiles, `docker-compose.yml`)\n",
    "  - Kubernetes (e.g., Pods, Deployments, Services)\n",
    "\n",
    "# Ethical and Responsible AI\n",
    "- Bias and Fairness\n",
    "  - Identifying and Mitigating Bias\n",
    "    - Data Bias Detection (e.g., `sklearn.metrics` fairness metrics)\n",
    "    - Algorithmic Fairness (e.g., Fairlearn toolkit)\n",
    "  - Fairness Metrics\n",
    "    - Demographic Parity\n",
    "    - Equalized Odds\n",
    "- Explainability and Interpretability\n",
    "  - LIME (Local Interpretable Model-agnostic Explanations)\n",
    "    - Using LIME (e.g., `lime.lime_tabular`)\n",
    "  - SHAP (SHapley Additive exPlanations)\n",
    "    - Using SHAP (e.g., `shap.TreeExplainer`, `shap.KernelExplainer`)\n",
    "  - Model-Specific Methods\n",
    "    - Feature Importance in Trees (e.g., `feature_importances_` in `sklearn.ensemble` models)\n",
    "- Privacy and Security\n",
    "  - Differential Privacy\n",
    "    - Adding Noise to Data\n",
    "    - Privacy-Preserving Mechanisms\n",
    "  - Federated Learning\n",
    "    - Training Across Multiple Devices\n",
    "    - Aggregating Results Securely\n",
    "  - Secure Multi-Party Computation\n",
    "    - Techniques and Protocols\n",
    "- Ethical Considerations in AI\n",
    "  - Ethical Guidelines (e.g., IEEE, ACM)\n",
    "  - Responsible AI Practices\n",
    "    - Transparency\n",
    "    - Accountability\n",
    "  - Case Studies and Best Practices\n",
    "    - Real-World Examples\n",
    "    - Lessons Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0aebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95878e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54252b48",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way. just different based on directory thing?\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d880a",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbddc23",
   "metadata": {},
   "source": [
    "resources:\n",
    "1. https://www.geeksforgeeks.org/data-preprocessing-machine-learning-python/?ref=header_search\n",
    "2. https://www.geeksforgeeks.org/ml-feature-scaling-part-2/\n",
    "3. http://localhost:8889/notebooks/tjyana/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/Preprocessing-Workflow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c10409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "# others: load_diabetes, load_digits, load_boston, load_breast_cancer, load_linnerud, load_sample_image, load_sample_images, load_wine\n",
    "\n",
    "# replacements for boston: \n",
    "\n",
    "# from sklearn.datasets import fetch_california_housing\n",
    "# housing = fetch_california_housing()\n",
    "\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data = data.data, columns = data.feature_names) # turn to df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69933750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8643bf",
   "metadata": {},
   "source": [
    "### Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1fa4ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates\n",
    "# df.duplicated() returns if duplicated or not \n",
    "\n",
    "# sum it with this\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffa4e4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove\n",
    "# df.drop_duplicates()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24cbfe",
   "metadata": {},
   "source": [
    "### Missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c7933",
   "metadata": {},
   "source": [
    "#### Identifying missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fe7b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isnull()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d852d6",
   "metadata": {},
   "source": [
    "#### Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160c3e0",
   "metadata": {},
   "source": [
    "##### remove rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values \n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c38b22",
   "metadata": {},
   "source": [
    "##### drop the column entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90230724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns='COLUMN_NAME', inplace=True) \n",
    "# CHECK THIS ONE BC NOT SURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d63f82",
   "metadata": {},
   "source": [
    "##### imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput missing values with mean, median, or mode \n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ad8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput with other data\n",
    "# df['COLUMN_NAME'].replace(np.nan, 'NEW_VALUE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d57716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use imputers\n",
    "# SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca058840",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1553292181.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    `df.isnull().sum()`\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "2. Encode categorical variables\n",
    "    - identify `df.select_dtypes(include=['object']).columns`\n",
    "    - choose encoding method\n",
    "        - one-hot\n",
    "            `pd.get_dummies(df, columns=caegorical_cols)`\n",
    "        - label\n",
    "            ```from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])```\n",
    "3. Feature scaling\n",
    "    - import `from sklearn.preprocessing import StandardScaler`\n",
    "    - choose scaling method\n",
    "        - StandardScaler\n",
    "            ```scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)```\n",
    "        - MinMaxScaler\n",
    "            ```from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cfbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a2111d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b70dda",
   "metadata": {},
   "source": [
    "# HEY LET'S TRY DOING ONE FULL PREPROCESS CYCLE BEFORE TAKING NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c00983",
   "metadata": {},
   "source": [
    "# YOU'RE TAKING TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb1889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54230172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9f64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b37ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(df.mean())\n",
    "train, test = train_test_split(df)\n",
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
