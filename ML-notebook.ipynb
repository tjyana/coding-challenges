{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ab141b",
   "metadata": {},
   "source": [
    "Machine Learning\n",
    "\n",
    "# Introduction to Machine Learning\n",
    "- Definition and Overview\n",
    "  - What is Machine Learning?\n",
    "  - History and Evolution\n",
    "  - Key Concepts and Terminology\n",
    "- Types of Machine Learning\n",
    "  - Supervised Learning\n",
    "    - Definition and Examples\n",
    "    - Use Cases\n",
    "    - Algorithms (e.g., `LinearRegression` from `sklearn.linear_model`)\n",
    "  - Unsupervised Learning\n",
    "    - Definition and Examples\n",
    "    - Use Cases\n",
    "    - Algorithms (e.g., `KMeans` from `sklearn.cluster`)\n",
    "  - Semi-supervised Learning\n",
    "    - Definition and Examples\n",
    "    - Use Cases\n",
    "    - Algorithms (e.g., Self-Training from `sklearn.semi_supervised`)\n",
    "  - Reinforcement Learning\n",
    "    - Definition and Examples\n",
    "    - Use Cases\n",
    "    - Algorithms (e.g., Q-Learning, Deep Q-Networks with `tensorflow` or `pytorch`)\n",
    "- Applications of Machine Learning\n",
    "  - Healthcare\n",
    "  - Finance\n",
    "  - Retail\n",
    "  - Autonomous Vehicles\n",
    "  - Natural Language Processing\n",
    "\n",
    "# Data Preprocessing\n",
    "- Data Cleaning\n",
    "  - Handling Missing Values\n",
    "    - Mean/Median Imputation (e.g., `SimpleImputer` from `sklearn.impute`)\n",
    "    - Dropping Missing Values (e.g., `dropna()` from `pandas`)\n",
    "    - Filling with Forward/Backward Fill (e.g., `fillna(method='ffill')` from `pandas`)\n",
    "  - Handling Outliers\n",
    "    - Z-Score Method (e.g., `scipy.stats.zscore`)\n",
    "    - IQR Method (e.g., using `quantile` from `pandas`)\n",
    "    - Winsorization (e.g., `winsorize` from `scipy.stats.mstats`)\n",
    "- Data Transformation\n",
    "  - Encoding Categorical Variables\n",
    "    - One-Hot Encoding (e.g., `OneHotEncoder` from `sklearn.preprocessing`)\n",
    "    - Label Encoding (e.g., `LabelEncoder` from `sklearn.preprocessing`)\n",
    "    - Binary Encoding (e.g., `binary` from `category_encoders`)\n",
    "  - Feature Scaling\n",
    "    - Normalization (Min-Max Scaling) (e.g., `MinMaxScaler` from `sklearn.preprocessing`)\n",
    "    - Standardization (Z-Score Scaling) (e.g., `StandardScaler` from `sklearn.preprocessing`)\n",
    "  - Feature Engineering\n",
    "    - Creating New Features (e.g., using `pandas`)\n",
    "    - Polynomial Features (e.g., `PolynomialFeatures` from `sklearn.preprocessing`)\n",
    "    - Interaction Features (e.g., using `pandas` and custom functions)\n",
    "    - Log Transformations (e.g., `numpy.log`)\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "- Descriptive Statistics\n",
    "  - Measures of Central Tendency (Mean, Median, Mode) (e.g., `mean`, `median`, `mode` from `numpy` or `pandas`)\n",
    "  - Measures of Dispersion (Variance, Standard Deviation, Range) (e.g., `var`, `std` from `numpy` or `pandas`)\n",
    "  - Skewness and Kurtosis (e.g., `skew`, `kurtosis` from `scipy.stats`)\n",
    "- Data Visualization Techniques\n",
    "  - Histograms (e.g., `hist` from `matplotlib.pyplot` or `seaborn`)\n",
    "  - Box Plots (e.g., `boxplot` from `matplotlib.pyplot` or `seaborn`)\n",
    "  - Scatter Plots (e.g., `scatter` from `matplotlib.pyplot` or `seaborn`)\n",
    "  - Pair Plots (e.g., `pairplot` from `seaborn`)\n",
    "  - Heatmaps (e.g., `heatmap` from `seaborn`)\n",
    "  - Violin Plots (e.g., `violinplot` from `seaborn`)\n",
    "- Identifying Patterns and Relationships\n",
    "  - Correlation Analysis\n",
    "    - Pearson Correlation (e.g., `corr` from `pandas`)\n",
    "    - Spearman Correlation (e.g., `spearmanr` from `scipy.stats`)\n",
    "  - Trend Analysis (e.g., using `pandas` time series methods)\n",
    "  - Detecting Seasonality (e.g., using `statsmodels.tsa`)\n",
    "\n",
    "# Supervised Learning\n",
    "- Regression Algorithms\n",
    "  - Linear Regression\n",
    "    - Assumptions\n",
    "    - Model Building (e.g., `LinearRegression` from `sklearn.linear_model`)\n",
    "    - Evaluation Metrics (MSE, RMSE, R²) (e.g., `mean_squared_error`, `r2_score` from `sklearn.metrics`)\n",
    "  - Polynomial Regression\n",
    "    - Polynomial Features (e.g., `PolynomialFeatures` from `sklearn.preprocessing`)\n",
    "    - Overfitting and Underfitting\n",
    "  - Ridge and Lasso Regression\n",
    "    - Regularization Techniques (e.g., `Ridge`, `Lasso` from `sklearn.linear_model`)\n",
    "    - Hyperparameter Tuning (α) (e.g., `GridSearchCV` from `sklearn.model_selection`)\n",
    "  - Support Vector Regression\n",
    "    - Kernel Trick (e.g., `SVR` from `sklearn.svm`)\n",
    "    - Epsilon-Insensitive Loss\n",
    "- Classification Algorithms\n",
    "  - Logistic Regression\n",
    "    - Sigmoid Function\n",
    "    - Thresholding\n",
    "    - ROC Curve and AUC (e.g., `roc_curve`, `auc` from `sklearn.metrics`)\n",
    "  - k-Nearest Neighbors (k-NN)\n",
    "    - Distance Metrics (Euclidean, Manhattan) (e.g., `KNeighborsClassifier` from `sklearn.neighbors`)\n",
    "    - Choosing k\n",
    "  - Support Vector Machines (SVM)\n",
    "    - Linear SVM\n",
    "    - Kernel SVM (RBF, Polynomial) (e.g., `SVC` from `sklearn.svm`)\n",
    "    - Hyperparameters (C, Gamma)\n",
    "  - Decision Trees\n",
    "    - Splitting Criteria (Gini, Entropy) (e.g., `DecisionTreeClassifier` from `sklearn.tree`)\n",
    "    - Pruning Techniques\n",
    "  - Random Forests\n",
    "    - Bagging (e.g., `RandomForestClassifier` from `sklearn.ensemble`)\n",
    "    - Feature Importance\n",
    "  - Gradient Boosting\n",
    "    - Boosting Principle\n",
    "    - Variants (AdaBoost, Gradient Boosting, XGBoost, LightGBM) (e.g., `GradientBoostingClassifier`, `XGBClassifier`, `LGBMClassifier`)\n",
    "  - Neural Networks\n",
    "    - Perceptrons\n",
    "    - Multilayer Perceptrons (MLP) (e.g., `MLPClassifier` from `sklearn.neural_network`)\n",
    "    - Activation Functions (ReLU, Sigmoid, Tanh)\n",
    "\n",
    "# Unsupervised Learning\n",
    "- Clustering Algorithms\n",
    "  - k-Means Clustering\n",
    "    - Choosing k (Elbow Method, Silhouette Score)\n",
    "    - Initial Centroid Selection (e.g., `KMeans` from `sklearn.cluster`)\n",
    "  - Hierarchical Clustering\n",
    "    - Agglomerative vs. Divisive\n",
    "    - Dendrograms (e.g., `AgglomerativeClustering` from `sklearn.cluster`, `dendrogram` from `scipy.cluster.hierarchy`)\n",
    "  - DBSCAN\n",
    "    - Density-Based Clustering\n",
    "    - Parameters (Epsilon, MinPts) (e.g., `DBSCAN` from `sklearn.cluster`)\n",
    "- Dimensionality Reduction\n",
    "  - Principal Component Analysis (PCA)\n",
    "    - Eigenvalues and Eigenvectors\n",
    "    - Explained Variance Ratio (e.g., `PCA` from `sklearn.decomposition`)\n",
    "  - t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "    - Perplexity\n",
    "    - Use Cases (e.g., `TSNE` from `sklearn.manifold`)\n",
    "  - Linear Discriminant Analysis (LDA)\n",
    "    - Maximizing Class Separability\n",
    "    - Comparison with PCA (e.g., `LinearDiscriminantAnalysis` from `sklearn.discriminant_analysis`)\n",
    "\n",
    "# Semi-Supervised Learning\n",
    "- Self-Training\n",
    "  - Pseudo-Labeling\n",
    "    - Confidence Thresholds\n",
    "    - Iterative Refinement\n",
    "- Co-Training\n",
    "  - View Selection\n",
    "    - Independent Feature Sets\n",
    "- Graph-Based Semi-Supervised Learning\n",
    "  - Label Propagation (e.g., `LabelPropagation` from `sklearn.semi_supervised`)\n",
    "  - Graph Convolutional Networks\n",
    "\n",
    "# Reinforcement Learning\n",
    "- Introduction to Reinforcement Learning\n",
    "  - Basics of RL\n",
    "  - Key Concepts: Agent, Environment, State, Action, Reward\n",
    "- Markov Decision Processes (MDP)\n",
    "  - States and Actions\n",
    "  - Transition Probabilities\n",
    "  - Rewards\n",
    "- Q-Learning\n",
    "  - Q-Table\n",
    "  - Bellman Equation\n",
    "  - Exploration vs. Exploitation\n",
    "- Deep Q-Networks (DQN)\n",
    "  - Neural Network Architecture (e.g., using `tensorflow` or `pytorch`)\n",
    "  - Experience Replay\n",
    "  - Target Networks\n",
    "- Policy Gradient Methods\n",
    "  - REINFORCE Algorithm\n",
    "  - Actor-Critic Methods\n",
    "  \n",
    "# Model Evaluation and Selection\n",
    "- Train/Test Split\n",
    "  - Holdout Validation\n",
    "  - Stratified Sampling\n",
    "- Cross-Validation\n",
    "  - k-Fold Cross-Validation\n",
    "    - Advantages and Disadvantages\n",
    "  - Leave-One-Out Cross-Validation\n",
    "    - Use Cases\n",
    "- Evaluation Metrics for Regression\n",
    "  - Mean Squared Error (MSE)\n",
    "  - Root Mean Squared Error (RMSE)\n",
    "  - Mean Absolute Error (MAE)\n",
    "  - R² Score\n",
    "- Evaluation Metrics for Classification\n",
    "  - Accuracy\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1 Score\n",
    "  - ROC Curve and AUC\n",
    "  - Confusion Matrix\n",
    "- Overfitting and Underfitting\n",
    "  - Bias-Variance Tradeoff\n",
    "  - Techniques to Mitigate Overfitting (Regularization, Pruning, Early Stopping)\n",
    "- Model Selection and Hyperparameter Tuning\n",
    "  - Grid Search\n",
    "  - Random Search\n",
    "  - Bayesian Optimization\n",
    "  \n",
    "# Ensemble Learning\n",
    "- Bagging\n",
    "  - Bootstrap Aggregating\n",
    "  - Random Forests\n",
    "    - Out-of-Bag Error\n",
    "- Boosting\n",
    "  - AdaBoost\n",
    "    - Weight Updates\n",
    "  - Gradient Boosting\n",
    "    - Gradient Descent\n",
    "    - Learning Rate\n",
    "  - XGBoost\n",
    "    - Regularization Parameters\n",
    "  - LightGBM\n",
    "    - Leaf-wise Growth\n",
    "- Stacking\n",
    "  - Base Models\n",
    "  - Meta-Model\n",
    "- Voting Classifiers\n",
    "  - Hard Voting\n",
    "  - Soft Voting\n",
    "  \n",
    "# Neural Networks and Deep Learning\n",
    "- Basics of Neural Networks\n",
    "  - Perceptrons\n",
    "  - Multilayer Perceptrons (MLP)\n",
    "    - Forward Propagation\n",
    "    - Backpropagation\n",
    "- Activation Functions\n",
    "  - Sigmoid\n",
    "  - Tanh\n",
    "  - ReLU\n",
    "  - Leaky ReLU\n",
    "- Training Neural Networks\n",
    "  - Gradient Descent\n",
    "    - Batch Gradient Descent\n",
    "    - Stochastic Gradient Descent\n",
    "    - Mini-Batch Gradient Descent\n",
    "  - Optimizers\n",
    "    - Adam\n",
    "    - RMSprop\n",
    "    - Adagrad\n",
    "- Convolutional Neural Networks (CNNs)\n",
    "  - Convolutional Layers\n",
    "  - Pooling Layers\n",
    "  - Fully Connected Layers\n",
    "  - Dropout Regularization\n",
    "- Recurrent Neural Networks (RNNs)\n",
    "  - Basic RNN\n",
    "  - Long Short-Term Memory (LSTM) Networks\n",
    "  - Gated Recurrent Unit (GRU)\n",
    "- Autoencoders\n",
    "  - Basic Autoencoder\n",
    "  - Denoising Autoencoder\n",
    "  - Variational Autoencoder (VAE)\n",
    "- Generative Adversarial Networks (GANs)\n",
    "  - Generator and Discriminator\n",
    "  - Training GANs\n",
    "  - Applications (Image Generation, Style Transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7fd82f",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a28ebd",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "  ### Tokenization (e.g., `word_tokenize` from `nltk`, `Tokenizer` from `keras.preprocessing.text`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca094c",
   "metadata": {},
   "source": [
    "- Word Tokenization\n",
    "- Sentence Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b70e4e",
   "metadata": {},
   "source": [
    "  ### Stop Words Removal (e.g., `stopwords` from `nltk.corpus`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3795ef",
   "metadata": {},
   "source": [
    "  ### Stemming (e.g., `PorterStemmer` from `nltk.stem`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b5fe7",
   "metadata": {},
   "source": [
    "  ### Lemmatization (e.g., `WordNetLemmatizer` from `nltk.stem`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13745cad",
   "metadata": {},
   "source": [
    "  ### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06608ea3",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f1575",
   "metadata": {},
   "source": [
    "  ### Bag-of-Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ada635",
   "metadata": {},
   "source": [
    "#### Count Vectorization (e.g., `CountVectorizer` from `sklearn.feature_extraction.text`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a72682",
   "metadata": {},
   "source": [
    "##### Vector Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55972283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'the young dog is running with the cat',\n",
    "    'running is good for your health',\n",
    "    'your cat is young',\n",
    "    'young young young young young cat cat cat'\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2139d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af366570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog', 'for', 'good', 'health', 'is', 'running', 'the',\n",
       "       'with', 'young', 'your'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9502ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert this to that grid thing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "vectorized_texts = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b867f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe360f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c03ae25e",
   "metadata": {},
   "source": [
    "##### Sparsity Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef864b",
   "metadata": {},
   "source": [
    "  ### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d0798",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization (e.g., `TfidfVectorizer` from `sklearn.feature_extraction.text`)\n",
    "      - Calculation\n",
    "      - Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ec077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couple go to a church party drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>the happy bastard quick movie review damn that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>it is movie like these that make a jaded movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest for camelot is warner bros first feature...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 target                                            reviews  \\\n",
       "0           0    neg  plot : two teen couples go to a church party ,...   \n",
       "1           1    neg  the happy bastard's quick movie review \\ndamn ...   \n",
       "2           2    neg  it is movies like these that make a jaded movi...   \n",
       "3           3    neg   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4           4    neg  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                       clean_reviews  target_encoded  \n",
       "0  plot two teen couple go to a church party drin...               0  \n",
       "1  the happy bastard quick movie review damn that...               0  \n",
       "2  it is movie like these that make a jaded movie...               0  \n",
       "3  quest for camelot is warner bros first feature...               0  \n",
       "4  synopsis a mentally unstable man undergoing ps...               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/movie_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b768783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x41596 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 643210 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying to column\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(data.clean_reviews)\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdfa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pipeline\n",
    "\n",
    "# Pipeline is probably simply better\n",
    "pipeline_tfidf_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# # make_pipeline is quicker but less customizable. can't give it the shortcuts for params:\n",
    "# pipeline_tfidf_nb = Pipeline(\n",
    "#     TfidfVectorizer(),\n",
    "#     MultinomialNB())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29faba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validate\n",
    "\n",
    "cv_results = cross_validate(pipeline_tfidf_nb, X, y, cv=5, scoring='accuracy')\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8d989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f67e7b7",
   "metadata": {},
   "source": [
    "  ### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa4970",
   "metadata": {},
   "source": [
    "   #### Word2Vec (e.g., `Word2Vec` from `gensim.models`)\n",
    "        - CBOW and Skip-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133092d7",
   "metadata": {},
   "source": [
    "   #### GloVe (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01e2cc",
   "metadata": {},
   "source": [
    "   #### FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737ee88",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "  ### Naive Bayes Classifier\n",
    "    - Multinomial Naive Bayes (e.g., `MultinomialNB` from `sklearn.naive_bayes`)\n",
    "  ### Support Vector Machines (SVM)\n",
    "    - Linear SVM for Text Classification (e.g., `LinearSVC` from `sklearn.svm`)\n",
    "  ### Recurrent Neural Networks (RNN)\n",
    "    - Long Short-Term Memory Networks (LSTM) (e.g., `LSTM` from `keras.layers`)\n",
    "    - Gated Recurrent Units (GRU)\n",
    "  ### Transformer Models\n",
    "    - Encoder-Decoder Architecture\n",
    "    - BERT (e.g., `transformers.BertModel` from `transformers` library)\n",
    "    - GPT (e.g., `transformers.GPT2Model` from `transformers` library)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd0fc3",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "  ### Recurrent Neural Networks (RNN)\n",
    "    - Character-Level RNNs\n",
    "  ### Transformer Models\n",
    "    - GPT-3, GPT-4 (e.g., `OpenAI API`)\n",
    "  ### Retrieval-Augmented Generation (RAG)\n",
    "    - Combining Retrieval and Generation (e.g., `transformers.RagTokenizer`, `transformers.RagModel` from `transformers` library)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b16bd",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "- Time Series Decomposition\n",
    "  - Additive and Multiplicative Models\n",
    "  - Trend, Seasonality, and Residuals\n",
    "- ARIMA Models\n",
    "  - Autoregressive (AR)\n",
    "  - Integrated (I)\n",
    "  - Moving Average (MA)\n",
    "  - ARIMA Model Building\n",
    "- Exponential Smoothing\n",
    "  - Simple Exponential Smoothing\n",
    "  - Holt’s Linear Trend Model\n",
    "  - Holt-Winters Seasonal Model\n",
    "- Long Short-Term Memory (LSTM) for Time Series\n",
    "  - Sequence Prediction\n",
    "  - Handling Long Sequences\n",
    "\n",
    "# Anomaly Detection\n",
    "- Techniques and Algorithms\n",
    "  - Statistical Methods\n",
    "    - Z-Score (e.g., `scipy.stats.zscore`)\n",
    "    - Grubbs' Test\n",
    "  - Proximity-Based Methods\n",
    "    - k-Nearest Neighbors (k-NN) (e.g., `LocalOutlierFactor` from `sklearn.neighbors`)\n",
    "    - DBSCAN (e.g., `DBSCAN` from `sklearn.cluster`)\n",
    "  - Clustering-Based Methods\n",
    "    - k-Means Clustering (e.g., `KMeans` from `sklearn.cluster`)\n",
    "    - Isolation Forest (e.g., `IsolationForest` from `sklearn.ensemble`)\n",
    "  - Machine Learning-Based Methods\n",
    "    - One-Class SVM (e.g., `OneClassSVM` from `sklearn.svm`)\n",
    "    - Autoencoders (e.g., using `tensorflow.keras` or `pytorch`)\n",
    "\n",
    "# Model Deployment\n",
    "- Saving and Loading Models\n",
    "  - Using Pickle (e.g., `pickle.dump`, `pickle.load`)\n",
    "  - Using Joblib (e.g., `joblib.dump`, `joblib.load`)\n",
    "- Model Serving\n",
    "  - REST APIs (Flask, FastAPI)\n",
    "    - Building API Endpoints (e.g., `flask.Flask`, `fastapi.FastAPI`)\n",
    "    - Handling Requests and Responses\n",
    "  - Web Services (Django, Flask)\n",
    "    - Integrating Machine Learning Models\n",
    "    - Handling User Inputs (e.g., `django.http`, `django.views`)\n",
    "  - Cloud Services (AWS SageMaker, Google AI Platform)\n",
    "    - Deploying Models\n",
    "    - Monitoring and Scaling\n",
    "- Monitoring and Maintenance\n",
    "  - Model Performance Monitoring\n",
    "    - Tracking Metrics Over Time\n",
    "    - Setting Alerts for Degradation\n",
    "  - A/B Testing\n",
    "    - Designing Experiments\n",
    "    - Analyzing Results\n",
    "  - Model Retraining\n",
    "    - Triggering Retraining\n",
    "    - Automating Pipelines\n",
    "\n",
    "# Tools and Libraries\n",
    "- Python Libraries\n",
    "  - NumPy (e.g., `numpy.array`, `numpy.linalg`)\n",
    "  - pandas (e.g., `pandas.DataFrame`, `pandas.Series`)\n",
    "  - scikit-learn (e.g., `sklearn.preprocessing`, `sklearn.model_selection`)\n",
    "  - TensorFlow (e.g., `tensorflow.keras`, `tensorflow.data`)\n",
    "  - Keras (e.g., `keras.models`, `keras.layers`)\n",
    "  - PyTorch (e.g., `torch.Tensor`, `torch.nn`)\n",
    "  - SciPy (e.g., `scipy.stats`, `scipy.optimize`)\n",
    "- Data Visualization Libraries\n",
    "  - Matplotlib (e.g., `matplotlib.pyplot.plot`, `matplotlib.pyplot.show`)\n",
    "  - Seaborn (e.g., `seaborn.scatterplot`, `seaborn.heatmap`)\n",
    "  - Plotly (e.g., `plotly.graph_objs`, `plotly.express`)\n",
    "  - Bokeh (e.g., `bokeh.plotting.figure`, `bokeh.io.show`)\n",
    "  - Altair (e.g., `alt.Chart`, `alt.data_transformers`)\n",
    "- Tools for Model Deployment\n",
    "  - Flask (e.g., `flask.Flask`, `flask.request`)\n",
    "  - Django (e.g., `django.http`, `django.views`)\n",
    "  - FastAPI (e.g., `fastapi.FastAPI`, `fastapi.Request`)\n",
    "  - Docker (e.g., Dockerfiles, `docker-compose.yml`)\n",
    "  - Kubernetes (e.g., Pods, Deployments, Services)\n",
    "\n",
    "# Ethical and Responsible AI\n",
    "- Bias and Fairness\n",
    "  - Identifying and Mitigating Bias\n",
    "    - Data Bias Detection (e.g., `sklearn.metrics` fairness metrics)\n",
    "    - Algorithmic Fairness (e.g., Fairlearn toolkit)\n",
    "  - Fairness Metrics\n",
    "    - Demographic Parity\n",
    "    - Equalized Odds\n",
    "- Explainability and Interpretability\n",
    "  - LIME (Local Interpretable Model-agnostic Explanations)\n",
    "    - Using LIME (e.g., `lime.lime_tabular`)\n",
    "  - SHAP (SHapley Additive exPlanations)\n",
    "    - Using SHAP (e.g., `shap.TreeExplainer`, `shap.KernelExplainer`)\n",
    "  - Model-Specific Methods\n",
    "    - Feature Importance in Trees (e.g., `feature_importances_` in `sklearn.ensemble` models)\n",
    "- Privacy and Security\n",
    "  - Differential Privacy\n",
    "    - Adding Noise to Data\n",
    "    - Privacy-Preserving Mechanisms\n",
    "  - Federated Learning\n",
    "    - Training Across Multiple Devices\n",
    "    - Aggregating Results Securely\n",
    "  - Secure Multi-Party Computation\n",
    "    - Techniques and Protocols\n",
    "- Ethical Considerations in AI\n",
    "  - Ethical Guidelines (e.g., IEEE, ACM)\n",
    "  - Responsible AI Practices\n",
    "    - Transparency\n",
    "    - Accountability\n",
    "  - Case Studies and Best Practices\n",
    "    - Real-World Examples\n",
    "    - Lessons Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0aebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95878e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54252b48",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way. just different based on directory thing?\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d880a",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbddc23",
   "metadata": {},
   "source": [
    "resources:\n",
    "1. https://www.geeksforgeeks.org/data-preprocessing-machine-learning-python/?ref=header_search\n",
    "2. https://www.geeksforgeeks.org/ml-feature-scaling-part-2/\n",
    "3. http://localhost:8889/notebooks/tjyana/05-ML/02-Prepare-the-dataset/data-preprocessing-workflow/Preprocessing-Workflow.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c10409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "# others: load_diabetes, load_digits, load_boston, load_breast_cancer, load_linnerud, load_sample_image, load_sample_images, load_wine\n",
    "\n",
    "# replacements for boston: \n",
    "\n",
    "# from sklearn.datasets import fetch_california_housing\n",
    "# housing = fetch_california_housing()\n",
    "\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data = data.data, columns = data.feature_names) # turn to df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69933750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8643bf",
   "metadata": {},
   "source": [
    "### Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1fa4ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates\n",
    "# df.duplicated() returns if duplicated or not \n",
    "\n",
    "# sum it with this\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffa4e4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "20635    -121.09  \n",
       "20636    -121.21  \n",
       "20637    -121.22  \n",
       "20638    -121.32  \n",
       "20639    -121.24  \n",
       "\n",
       "[20640 rows x 8 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove\n",
    "# df.drop_duplicates()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24cbfe",
   "metadata": {},
   "source": [
    "### Missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c7933",
   "metadata": {},
   "source": [
    "#### Identifying missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fe7b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isnull()\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d852d6",
   "metadata": {},
   "source": [
    "#### Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160c3e0",
   "metadata": {},
   "source": [
    "##### remove rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values \n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c38b22",
   "metadata": {},
   "source": [
    "##### drop the column entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90230724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns='COLUMN_NAME', inplace=True) \n",
    "# CHECK THIS ONE BC NOT SURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d63f82",
   "metadata": {},
   "source": [
    "##### imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput missing values with mean, median, or mode \n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ad8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imput with other data\n",
    "# df['COLUMN_NAME'].replace(np.nan, 'NEW_VALUE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90d57716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use imputers\n",
    "# SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca058840",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1553292181.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    `df.isnull().sum()`\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "2. Encode categorical variables\n",
    "    - identify `df.select_dtypes(include=['object']).columns`\n",
    "    - choose encoding method\n",
    "        - one-hot\n",
    "            `pd.get_dummies(df, columns=caegorical_cols)`\n",
    "        - label\n",
    "            ```from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])```\n",
    "3. Feature scaling\n",
    "    - import `from sklearn.preprocessing import StandardScaler`\n",
    "    - choose scaling method\n",
    "        - StandardScaler\n",
    "            ```scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)```\n",
    "        - MinMaxScaler\n",
    "            ```from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cfbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a2111d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b70dda",
   "metadata": {},
   "source": [
    "# HEY LET'S TRY DOING ONE FULL PREPROCESS CYCLE BEFORE TAKING NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c00983",
   "metadata": {},
   "source": [
    "# YOU'RE TAKING TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb1889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54230172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9f64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b37ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(df.mean())\n",
    "train, test = train_test_split(df)\n",
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
